{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tacotron 2 Model definition\n",
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, n_mel_channels=80, n_symbols=2000, n_speakers=1):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.embedding = nn.Embedding(n_symbols, 512)\n",
    "        self.encoder = nn.LSTM(512, 512, batch_first=True)\n",
    "        self.decoder = nn.LSTM(512 + n_mel_channels, 512, batch_first=True)  # Adjusted to handle concatenated inputs\n",
    "        self.mel_projection = nn.Linear(512, n_mel_channels)\n",
    "\n",
    "    def forward(self, text, mel_input):\n",
    "        embedded_text = self.embedding(text)\n",
    "        encoder_outputs, (h_n, c_n) = self.encoder(embedded_text)\n",
    "        \n",
    "        # Repeat encoder hidden state across time steps\n",
    "        repeated_h_n = h_n.repeat(mel_input.size(1), 1, 1).permute(1, 0, 2)\n",
    "        repeated_c_n = c_n.repeat(mel_input.size(1), 1, 1).permute(1, 0, 2)\n",
    "\n",
    "        # Concatenate encoder outputs with mel_input for the decoder\n",
    "        decoder_input = torch.cat((repeated_h_n, mel_input), dim=-1)\n",
    "\n",
    "        decoder_outputs, _ = self.decoder(decoder_input, (h_n, c_n))\n",
    "        mel_outputs = self.mel_projection(decoder_outputs)\n",
    "        return mel_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class TTSDataset(data.Dataset):\n",
    "    def __init__(self, text_files, mel_files):\n",
    "        self.text_files = text_files\n",
    "        self.mel_files = mel_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.load_text(self.text_files[idx])\n",
    "        mel = self.load_mel(self.mel_files[idx])\n",
    "        return text, mel\n",
    "\n",
    "    def load_text(self, text_file):\n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read().strip()\n",
    "        # Convert text to Unicode code points\n",
    "        text_indices = [ord(char) for char in text]\n",
    "        return torch.tensor(text_indices, dtype=torch.long)\n",
    "\n",
    "    def load_mel(self, mel_file):\n",
    "        mel, _ = librosa.load(mel_file, sr=22050)\n",
    "        mel = librosa.feature.melspectrogram(y=mel, sr=22050, n_mels=80)\n",
    "        mel = librosa.power_to_db(mel, ref=np.max)\n",
    "        return torch.tensor(mel, dtype=torch.float32).T  # Transpose for (time, mel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding function\n",
    "def collate_fn(batch):\n",
    "    texts, mels = zip(*batch)\n",
    "    \n",
    "    text_lengths = [len(t) for t in texts]\n",
    "    mel_lengths = [len(m) for m in mels]\n",
    "    \n",
    "    max_text_len = max(text_lengths)\n",
    "    max_mel_len = max(mel_lengths)\n",
    "    \n",
    "    padded_texts = torch.zeros(len(texts), max_text_len, dtype=torch.long)\n",
    "    padded_mels = torch.zeros(len(mels), max_mel_len, mels[0].size(1))\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        padded_texts[i, :text_lengths[i]] = texts[i]\n",
    "        padded_mels[i, :mel_lengths[i], :] = mels[i]\n",
    "    \n",
    "    return padded_texts, padded_mels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('archive/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_name(row):\n",
    "  # print(row.values)\n",
    "  value = row.values[0]\n",
    "  # print(value)\n",
    "  return value[value.find('|')+1:]\n",
    "\n",
    "def find_file_text(row):\n",
    "  value = row.values[0]\n",
    "  return value[:value.find('|')].replace('\\u200c', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['file'] = np.array([\"archive/wavs/\"+find_file_name(row) for row in metadata.iloc])\n",
    "metadata['file_name'] = np.array([find_file_name(row) for row in metadata.iloc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['text'] = np.array([find_file_text(row) for row in metadata.iloc])\n",
    "metadata['text_file'] = np.array([\"archive/text/\"+find_file_name(row)[:-3]+\"txt\" for row in metadata.iloc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in metadata.iloc:\n",
    "    file_path = os.path.join('archive/text', row['file_name'][:-3]+\"txt\")\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_files = ['path/to/text1.txt', 'path/to/text2.txt', ...]\n",
    "# mel_files = ['path/to/mel1.wav', 'path/to/mel2.wav', ...]\n",
    "\n",
    "dataset = TTSDataset(metadata['text_file'].values, metadata['file'].values)\n",
    "dataloader = data.DataLoader(dataset, batch_size=200, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 506.21783447265625\n",
      "Epoch 2/10, Loss: 502.0771179199219\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[262], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m Tacotron2()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[262], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m     mel_pred \u001b[38;5;241m=\u001b[39m model(text, mel_input)\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(mel_pred, mel_target)\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train(model, dataloader, num_epochs=10, learning_rate=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for text, mel in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            mel_input = mel[:, :-1, :]\n",
    "            mel_target = mel[:, 1:, :]\n",
    "            # print(len(text[0]))\n",
    "\n",
    "            mel_pred = model(text, mel_input)\n",
    "            loss = criterion(mel_pred, mel_target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "model = Tacotron2()\n",
    "train(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(model, text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([ord(c) for c in text]).unsqueeze(0)\n",
    "        mel_input = torch.zeros((1, 1, 80))\n",
    "        mel_output = model(text, mel_input)\n",
    "    return mel_output.squeeze().cpu().numpy()\n",
    "\n",
    "mel_output = synthesize(model, \"Sample text\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
